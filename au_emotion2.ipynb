{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import os as os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs: empty array of 593 frames x 68 AAMs \n",
    "# outputs: 593 frames x 64 AUs array of 0s\n",
    "aam = [[0]*136 for _ in range(593)] \n",
    "aam0 = [[0]*136 for _ in range(593)] \n",
    "aamvec = [[0]*136 for _ in range(593)] \n",
    "au = [[0]*64 for _ in range(593)] \n",
    "emotion = [[0]*7 for _ in range(593)]\n",
    "# aam = []\n",
    "# au = []\n",
    "# emotion = []\n",
    "\n",
    "# au2d looks like:\n",
    "# AUs     0   1   2  ...  63\n",
    "# ------------------------\n",
    "# frame \n",
    "# 0     | 0 | 1 | 0 | ... \n",
    "# ------------------------\n",
    "# 1     | 0 | 1 | 1 | ... \n",
    "# ------------------------\n",
    "# 2     | 1 | 1 | 0 | ... \n",
    "# ------------------------\n",
    "# ...\n",
    "# 592\n",
    "\n",
    "# Open and read the output dataset (AU)\n",
    "for i, filename in enumerate(os.listdir(\"au\")):\n",
    "    # first i is .DS_store\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(\"au/\" + filename) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                els = line.split()\n",
    "                if els:\n",
    "                    if els[0][len(els[0]) - 1] == \"0\":\n",
    "                        au[i - 1][int(els[0][0]) - 1] = 1\n",
    "                    else:\n",
    "                        au[i - 1][int(els[0][0] + els[0][2]) - 1] = 1\n",
    "            f.close()\n",
    "\n",
    "# for frame in au2d:\n",
    "#     au.append([feature for feature in frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs looks like: \n",
    "# AAMs         0           1      ... 67\n",
    "# -------------------------------------\n",
    "# frame \n",
    "# 0     | 1.2 | 3.4 | .2 | 3 | ...\n",
    "# -------------------------------------\n",
    "# 1     | [6.5, 3] | [2.2, 3.1] | ...\n",
    "# -------------------------------------\n",
    "# 2     | [5.4, 2.2] | [.9, 2.9] | ...\n",
    "# -------------------------------------\n",
    "# ...\n",
    "# 592\n",
    "\n",
    "for i, filename in enumerate(os.listdir(\"aam\")):\n",
    "    # first i is .DS_store\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(\"aam/\" + filename) as f:\n",
    "            lines = f.readlines()\n",
    "            for j, line in enumerate(lines):\n",
    "                els = line.split()\n",
    "                if els:\n",
    "                    aam[i - 1][2 * j] = float(els[0])\n",
    "                    aam[i - 1][2 * j + 1] = float(els[1])\n",
    "#                     aam[i - 1][j] = [float(els[0]), float(els[1])]\n",
    "            f.close()\n",
    "for i, filename in enumerate(os.listdir(\"aamvec\")):\n",
    "    # first i is .DS_store\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(\"aamvec/\" + filename) as f:\n",
    "            lines = f.readlines()\n",
    "            for j, line in enumerate(lines):\n",
    "                els = line.split()\n",
    "                if els:\n",
    "                    aam0[i - 1][2 * j] = float(els[0])\n",
    "                    aam0[i - 1][2 * j + 1] = float(els[1])\n",
    "#                     aam[i - 1][j] = [float(els[0]), float(els[1])]\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only 327 out of 593 are coded\n",
    "# non-coded ones are given -1 as class\n",
    "# 0 = neutral\n",
    "# 1 = anger\n",
    "# 2 = contempt\n",
    "# 3 = disgust\n",
    "# 4 = fear\n",
    "# 5 = happy\n",
    "# 6 = sadness\n",
    "# 7 = surprise\n",
    "\n",
    "for i, filename in enumerate(os.listdir(\"emo\")):\n",
    "    # first i is .DS_store\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(\"emo/\" + filename) as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                els = line.split() # except last character\n",
    "                if els:\n",
    "                    if (int(float(els[0])) == -1):\n",
    "                        for e in range(7):\n",
    "                            emotion[i-1][e] = -1\n",
    "                    else: \n",
    "                        emotion[i - 1][int(float(els[0])) - 1] = 1\n",
    "            f.close()\n",
    "            \n",
    "# for frame in emotion2d:\n",
    "#     emotion.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(593):\n",
    "    for j in range(136):\n",
    "        aamvec[i][j] = float(\"%.1f\" % (aam[i][j] - aam0[i][j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "cl_lr = LinearRegression()\n",
    "cl_lda = LinearDiscriminantAnalysis()\n",
    "cl_krg = KernelRidge()\n",
    "cl_svm = SVC()\n",
    "cl_sgd = SGDClassifier()\n",
    "cl_knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "cl_knn10 = KNeighborsClassifier(n_neighbors=10)\n",
    "cl_knn15 = KNeighborsClassifier(n_neighbors=15)\n",
    "cl_gp = GaussianProcess()\n",
    "cl_cd = CCA()\n",
    "cl_nb = GaussianNB()\n",
    "cl_dt = DecisionTreeClassifier()\n",
    "cl_ab = AdaBoostClassifier()\n",
    "cl_mc = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "cl_lp = LabelPropagation()\n",
    "cl_ir = IsotonicRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n=593, n_folds=593)\n",
    "train_input = []\n",
    "train_output = []\n",
    "\n",
    "vlr = 0\n",
    "vlda = 0\n",
    "vkrg = 0\n",
    "vsvm = 0\n",
    "vsgd = 0\n",
    "vknn5 = 0\n",
    "vknn10 = 0\n",
    "vknn15 = 0\n",
    "vgp = 0\n",
    "vcd = 0\n",
    "vnb = 0\n",
    "vdt = 0\n",
    "vab = 0\n",
    "vmc = 0\n",
    "vlp = 0\n",
    "vir = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_input = []\n",
    "# train_output = []\n",
    "# for (train_index, test_index) in kf:\n",
    "#     for idx in train_index:\n",
    "#         if (emotion[idx] != -1):\n",
    "#             train_input.append(au[idx])\n",
    "#             train_output.append(emotion[idx])\n",
    "#     cl_lr.fit(train_input, train_output)\n",
    "#     vlr += cl_lr.score(au[test_index], [emotion[test_index]])\n",
    "    \n",
    "#     train_input = []\n",
    "#     train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "train_input = []\n",
    "train_output = []\n",
    "vlda = 0\n",
    "vsvm = 0\n",
    "vsgd = 0\n",
    "vknn5 = 0\n",
    "vknn10 = 0\n",
    "vknn15 = 0\n",
    "vnb = 0\n",
    "vdt = 0\n",
    "vab = 0\n",
    "vlp = 0\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx][0] != -1):\n",
    "            train_input.append(au[idx])\n",
    "    for idxemo in range(7):\n",
    "        for idx in train_index:\n",
    "            if (emotion[idx][0] != -1):                \n",
    "                train_output.append(emotion[idx][idxemo])\n",
    "        cl_lda.fit(train_input, train_output)\n",
    "        vlda += cl_lda.score(au[test_index], [emotion[test_index][idxemo]])    \n",
    "        cl_svm.fit(train_input, train_output)\n",
    "        vsvm += cl_svm.score(au[test_index], [emotion[test_index][idxemo]]) \n",
    "        cl_sgd.fit(train_input, train_output)\n",
    "        vsgd += cl_sgd.score(au[test_index], [emotion[test_index][idxemo]])\n",
    "        cl_knn5.fit(train_input, train_output)\n",
    "        vknn5 += cl_knn5.score(au[test_index], [emotion[test_index][idxemo]])   \n",
    "        cl_knn10.fit(train_input, train_output)\n",
    "        vknn10 += cl_knn10.score(au[test_index], [emotion[test_index][idxemo]])   \n",
    "        cl_knn15.fit(train_input, train_output)\n",
    "        vknn15 += cl_knn15.score(au[test_index], [emotion[test_index][idxemo]])   \n",
    "        cl_nb.fit(train_input, train_output)\n",
    "        vnb += cl_nb.score(au[test_index], [emotion[test_index][idxemo]])\n",
    "        cl_dt.fit(train_input, train_output)\n",
    "        vdt += cl_dt.score(au[test_index], [emotion[test_index][idxemo]])  \n",
    "        cl_ab.fit(train_input, train_output)\n",
    "        vab += cl_ab.score(au[test_index], [emotion[test_index][idxemo]])\n",
    "        cl_lp.fit(train_input, train_output)\n",
    "        vlp += cl_lp.score(au[test_index], [emotion[test_index][idxemo]])\n",
    "        train_output = []\n",
    "    train_input = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_input = []\n",
    "# train_output = []\n",
    "# for (train_index, test_index) in kf:\n",
    "#     for idx in train_index:\n",
    "#         if (emotion[idx] != -1):\n",
    "#             train_input.append(au[idx])\n",
    "#             train_output.append(emotion[idx])\n",
    "        \n",
    "#     cl_krg.fit(train_input, train_output) \n",
    "#     vkrg += cl_krg.score(au[test_index], [emotion[test_index]])\n",
    "    \n",
    "#     train_input = []\n",
    "#     train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_svm.fit(train_input, train_output)\n",
    "    vsvm += cl_svm.score(au[test_index], [emotion[test_index]])   \n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_sgd.fit(train_input, train_output)\n",
    "    vsgd += cl_sgd.score(au[test_index], [emotion[test_index]])\n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_knn5.fit(train_input, train_output)\n",
    "    vknn5 += cl_knn5.score(au[test_index], [emotion[test_index]])   \n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_knn10.fit(train_input, train_output)\n",
    "    vknn10 += cl_knn10.score(au[test_index], [emotion[test_index]])   \n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_knn15.fit(train_input, train_output) \n",
    "    vknn15 += cl_knn15.score(au[test_index], [emotion[test_index]])   \n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_input = []\n",
    "# train_output = []\n",
    "# for (train_index, test_index) in kf:\n",
    "#     for idx in train_index:\n",
    "#         if (emotion[idx] != -1):\n",
    "#             train_input.append(au[idx])\n",
    "#             train_output.append(emotion[idx])\n",
    "        \n",
    "#     cl_cd.fit(train_input, train_output)\n",
    "#     vcd += cl_cd.score(au[test_index], [emotion[test_index]])   \n",
    "    \n",
    "#     train_input = []\n",
    "#     train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_nb.fit(train_input, train_output)\n",
    "    vnb += cl_nb.score(au[test_index], [emotion[test_index]])\n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_dt.fit(train_input, train_output)\n",
    "    vdt += cl_dt.score(au[test_index], [emotion[test_index]])   \n",
    "\n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_ab.fit(train_input, train_output)\n",
    "    vab += cl_ab.score(au[test_index], [emotion[test_index]])\n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [ 1 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0fb7e219fc35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcl_mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mvmc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcl_mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mau\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anzuhakone/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anzuhakone/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anzuhakone/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anzuhakone/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 176\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [ 1 64]"
     ]
    }
   ],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_mc.fit(train_input, train_output)\n",
    "    vmc += cl_mc.score(au[test_index], [emotion[test_index]]) \n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_lp.fit(train_input, train_output)\n",
    "    vlp += cl_lp.score(au[test_index], [emotion[test_index]])\n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X should be a 1d array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5625657099aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtrain_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcl_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvir\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcl_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mau\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anzuhakone/anaconda/lib/python2.7/site-packages/sklearn/isotonic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \"\"\"\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# Build y_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# Handle the left and right bounds on X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anzuhakone/anaconda/lib/python2.7/site-packages/sklearn/isotonic.pyc\u001b[0m in \u001b[0;36m_build_y\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# Determine increasing if auto-determination requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anzuhakone/anaconda/lib/python2.7/site-packages/sklearn/isotonic.pyc\u001b[0m in \u001b[0;36m_check_fit_data\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_fit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X should be a 1d array\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X should be a 1d array"
     ]
    }
   ],
   "source": [
    "train_input = []\n",
    "train_output = []\n",
    "for (train_index, test_index) in kf:\n",
    "    for idx in train_index:\n",
    "        if (emotion[idx] != -1):\n",
    "            train_input.append(au[idx])\n",
    "            train_output.append(emotion[idx])\n",
    "        \n",
    "    cl_ir.fit(train_input, train_output)\n",
    "    vir += cl_ir.score(au[test_index], [emotion[test_index]]) \n",
    "    \n",
    "    train_input = []\n",
    "    train_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.968531468531\n",
      "SVM: 0.946241258741\n",
      "SGD: 0.956293706294\n",
      "KNN5: 0.972027972028\n",
      "KNN10: 0.97027972028\n",
      "KNN15: 0.964597902098\n",
      "NB: 0.693181818182\n",
      "DT: 0.958916083916\n",
      "adaboost: 0.963286713287\n",
      "LP: 0.968968531469\n"
     ]
    }
   ],
   "source": [
    "# print(\"Linear regression: \" + str(vlr / (len(train_input) - 1.)))\n",
    "print(\"LDA: \" + str(vlda / 2288.))\n",
    "# print(\"KRG: \" + str(vkrg / (len(train_input) - 1.)))\n",
    "print(\"SVM: \" + str(vsvm / 2288.))\n",
    "print(\"SGD: \" + str(vsgd / 2288.))\n",
    "print(\"KNN5: \" + str(vknn5 / 2288.))\n",
    "print(\"KNN10: \" + str(vknn10 / 2288.))\n",
    "print(\"KNN15: \" + str(vknn15 / 2288.))\n",
    "# print(\"GP: \" + str(vgp / (len(train_input) - 1.)))\n",
    "# print(\"CD: \" + str(vcd / (len(train_input) - 1.)))\n",
    "print(\"NB: \" + str(vnb / 2288.))\n",
    "print(\"DT: \" + str(vdt / 2288.))\n",
    "print(\"adaboost: \" + str(vab / 2288.))\n",
    "# print(\"MC: \" + str(vmc / (len(train_input) - 1.)))\n",
    "print(\"LP: \" + str(vlp / 2288.))\n",
    "# print(\"IR: \" + str(vir / (len(train_input) - 1.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325.0\n"
     ]
    }
   ],
   "source": [
    "print (len(train_input) - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for (train_index, test_index) in kf:\n",
    "#     for idx in train_index:\n",
    "#         train_input.append(aam[idx])\n",
    "#         train_output.append(emotion[idx])\n",
    "        \n",
    "#     cl_lr.fit(train_input, train_output)\n",
    "#     cl_lda.fit(train_input, train_output)\n",
    "#     cl_krg.fit(train_input, train_output)\n",
    "#     cl_svm.fit(train_input, train_output)\n",
    "#     cl_sgd.fit(train_input, train_output)\n",
    "#     cl_knn5.fit(train_input, train_output)\n",
    "#     cl_knn10.fit(train_input, train_output)\n",
    "#     cl_knn15.fit(train_input, train_output)\n",
    "# #     cl_gp.fit(train_input, train_output)\n",
    "#     cl_cd.fit(train_input, train_output)\n",
    "#     cl_nb.fit(train_input, train_output)\n",
    "#     cl_dt.fit(train_input, train_output)\n",
    "#     cl_ab.fit(train_input, train_output)\n",
    "#     cl_mc.fit(train_input, train_output)\n",
    "#     cl_lp.fit(train_input, train_output)\n",
    "#     cl_ir.fit(train_input, train_output)\n",
    "    \n",
    "#     vlr += cl_lr.score(au[test_index], [emotion[test_index]])\n",
    "#     vlda += cl_lda.score(aam[test_index], [emotion[test_index]])    \n",
    "#     vkrg += cl_krg.score(aam[test_index], [emotion[test_index]])\n",
    "#     vsvm += cl_svm.score(aam[test_index], [emotion[test_index]])   \n",
    "#     vsdg += cl_sdg.score(aam[test_index], [emotion[test_index]])\n",
    "#     vknn5 += cl_knn.score(aam[test_index], [emotion[test_index]])   \n",
    "#     vknn10 += cl_knn.score(aam[test_index], [emotion[test_index]])   \n",
    "#     vknn15 += cl_knn.score(aam[test_index], [emotion[test_index]])   \n",
    "# #     vgp += cl_gp.score(aam[test_index], [emotion[test_index]])\n",
    "#     vcd += cl_cd.score(aam[test_index], [emotion[test_index]])   \n",
    "#     vnb += cl_nb.score(aam[test_index], [emotion[test_index]])\n",
    "#     vdt += cl_dt.score(aam[test_index], [emotion[test_index]])   \n",
    "#     vab += cl_ab.score(aam[test_index], [emotion[test_index]])\n",
    "#     vmc += cl_mc.score(aam[test_index], [emotion[test_index]]) \n",
    "#     vlp += cl_lp.score(aam[test_index], [emotion[test_index]])\n",
    "#     vir += cl_ir.score(aam[test_index], [emotion[test_index]]) \n",
    "    \n",
    "#     train_input = []\n",
    "#     train_output = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
